{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "21_Transformer(미완).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PQSnsGeA2OH"
      },
      "source": [
        "# 트랜스포머 (Transformer)\n",
        "\n",
        "* 참고: https://wikidocs.net/31379"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbQ-h_XxBAiq"
      },
      "source": [
        "* attention mechanism은 seq2seq의 입력 시퀀스 정보 손실을 보정해주기 위해 사용됨\n",
        "* attention mechanism을 보정 목적이 아닌, 인코더와 디코더로 구성한 모델이 바로 트랜스포머\n",
        "* 트랜스포머는 RNN을 사용하지 않고 인코더와 디코더를 설계하였으며, 성능도 RNN보다 우수함\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "LJD6L7cNx8sv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDiFPIdUBBS2"
      },
      "source": [
        "## 포지셔널 인코딩"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLqHf_4SEWoa"
      },
      "source": [
        "* 기존의 RNN은 단어의 위치를 따라 순차적으로 입력받아 단어의 위치정보를 활용할 수 있었음\n",
        "* 트랜스포머의 경우, RNN을 활용하지 않았기 때문에 단어의 위치정보를 다른 방식으로 줄 필요가 있음\n",
        "* 이를 위해 **각 단어의 임베딩 벡터에 위치 정보들을 더하게 되는데** 이를 포지셔널 인코딩이라 함\n",
        "* 보통 포지셔널 인코딩은 sin, cos을 이용하여 계산"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiO5c_HIFBAk"
      },
      "source": [
        "def positional_encoding(dim, sentence_length):\n",
        "    encoded_vec = np.array([pos / np.power(10000, 2*i/dim) for pos in range(sentence_length) for i in range(dim)])\n",
        "    encoded_vec[::2] = np.sin(encoded_vec[::2])\n",
        "    encoded_vec[1::2] = np.cos(encoded_vec[1::2])\n",
        "    return tf.constant(encoded_vec.reshape([sentence_length, dim]), dtype=np.float32)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "099gUUxhAgy3"
      },
      "source": [
        "## 레이어 정규화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCdips98yPuH"
      },
      "source": [
        "*  레이어 정규화에서는 텐서의 마지막 차원에 대해 평균과 분산을 구하고, 이 값을 통해 값을 정규화함\n",
        "*  해당 정규화를 각 층의 연결에 편리하게 적용하기 위해 함수화한 `sublayer_connection()`을 선언"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSJjxF86Aeg3"
      },
      "source": [
        "def layer_norm(inputs, eps=1e-6):\n",
        "    feature_shape = inputs.get_shape()[-1:]\n",
        "    mean = tf.keras.backend.mean(inputs, [-1], keepdims=True)\n",
        "    std = tf.keras.backend.std(inputs, [-1], keepdims=True)\n",
        "    beta = tf.Variable(tf.zeros(feature_shape), trainable=False)\n",
        "    gamma = tf.Variable(tf.ones(feature_shape), trainable=False)\n",
        "    return gamma * (inputs - mean) / (std + eps) + beta"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km9ORxIun-MU"
      },
      "source": [
        "def sublayer_connection(inputs, sublayer, dropout=0.2):\n",
        "    outputs = layer_norm(inputs + tf.keras.layers.Dropout(dropout)(sublayer))\n",
        "    return outputs"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ppb7IxJ3diMC"
      },
      "source": [
        "## 어텐션"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JaU6MHgy9V2"
      },
      "source": [
        "\n",
        "\n",
        "*   트랜스포머 모델의 핵심이 되는 부분\n",
        "*   트랜스포머에서는 multi-head attention과 self attention이라는 개념을 사용\n",
        "  1.   multi-head attention\n",
        "      * 디코더가 가지는 차원을 나누어 병렬로 어텐션을 진행\n",
        "      *  마지막엔 병렬로 각 진행해 얻은 어텐션 헤드를 모두 연결\n",
        "      * 이로 인해 다양한 시각에서 정보를 수집할 수 있는 효과를 얻음\n",
        "  2.   self attention\n",
        "      *   일반적인 어텐션의 경우, 특정 시점의 디코더 은닉상태와 모든 시점의 인코더 은닉상태를 활용\n",
        "      *   이는 입력 문장과 다른 문장에 존재하는 단어간의 어텐션을 의미함\n",
        "      *   반면 self attention은 은닉 상태를 동일하게 하여 어텐션을 진행\n",
        "      *   이는 입력 문장 내 단어간의 어텐션을 의미함\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   트랜스포머 제안 논문에서는 scaled-dot product attention을 활용해 모델을 작성함\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRyL0KDXi6ej"
      },
      "source": [
        "### scaled-dot product attention 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HtmcgRR3Cr-"
      },
      "source": [
        "* scaled-dot product attention은 앞서 학습한 dot product attention과 거의 유사함\n",
        "* 단 attention을 진행할 때 어텐션 스코어를 계산할 때 내적 값을 정규화\n",
        "* 트랜스포머에서는 정규화할 때 K 벡터(=디코더 셀의 은닉 상태)의 차원을 루트를 취한 값을 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALEMzi4fdiSQ"
      },
      "source": [
        "def scaled_dot_product_attention(query, key, value, masked=False):\n",
        "    key_dim_size = float(key.get_shape().as_list()[-1])\n",
        "    key = tf.transpose(key, perm=[0, 2, 1])\n",
        "    outputs = tf.matmul(query, key) / tf.sqrt(key_dim_size)\n",
        "\n",
        "    if masked:\n",
        "        diag_vals = tf.ones_like(outputs[0, :, :])\n",
        "        tril = tf.linalg.LinearOperatorLowerTriangular(diag_vals).to_dense()\n",
        "        masks = tf.tile(tf.expand_dims(tril, 0), [tf.shape(outputs)[0], 1, 1])\n",
        "        paddings = tf.ones_like(masks) * (-2 ** 30)\n",
        "        outputs =tf.where(tf.equal(masks, 0), paddings, outputs)\n",
        "\n",
        "    attention_map = tf.nn.softmax(outputs)\n",
        "    return tf.matmul(attention_map, value)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr20BxvVi-8b"
      },
      "source": [
        "### multi-head attention 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb5qflUH14-H"
      },
      "source": [
        "* multi-head attention의 구현 과정\n",
        "  1. query, key, value에 해당하는 값을 받고, 해당 값에 해당하는 행렬 생성\n",
        "  2. 생성된 행렬들을 heads에 해당하는 수만큼 분리\n",
        "  3. 분리한 행렬들에 대해 각각 어텐션을 수행\n",
        "  4. 각 어텐션 결과들을 연결해 최종 어텐션 결과 생성\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooc3FAdQi_Gz"
      },
      "source": [
        "def multi_head_attention(query, key, value, num_units, heads, masked=False):\n",
        "    query = tf.keras.layers.Dense(num_units, activation=tf.nn.relu)(query)\n",
        "    key = tf.keras.layers.Dense(num_units, activation=tf.nn.relu)(key)\n",
        "    value = tf.keras.layers.Dense(num_units, activation=tf.nn.relu)(value)\n",
        "\n",
        "    query = tf.concat(tf.split(query, heads, axis=-1), axis=0)\n",
        "    key = tf.concat(tf.split(key, heads, axis=-1), axis=0)\n",
        "    value = tf.concat(tf.split(value, heads, axis=-1), axis=0)\n",
        "\n",
        "    attention_map = scaled_dot_product_attention(query, key, value, masked)\n",
        "    attn_outputs = tf.concat(tf.split(attention_map, heads, axis=0), axis=-1)\n",
        "    attn_outputs = tf.keras.layers.Dense(num_units, activation=tf.nn.relu)(attn_outputs)\n",
        "    return attn_outputs"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78Zn5-fYITD4"
      },
      "source": [
        "## 포지션-와이즈 피드 포워드 신경망"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xxeG2xvo3ZN"
      },
      "source": [
        "\n",
        "\n",
        "*   multi-head attention의 결과인 행렬을 입력받아 연산\n",
        "*   일반적인 완전 연결 신경망(Dense layer)를 사용\n",
        "*   position-wise FFNN은 인코더와 디코더에 모두 존재\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tSFd5OaITJ0"
      },
      "source": [
        "def feed_forward(inputs, num_units):\n",
        "    feature_shape = inputs.get_shape()[-1]\n",
        "    inner_layer = tf.keras.layers.Dense(num_units, activation=tf.nn.relu)(inputs)\n",
        "    outputs = tf.keras.layers.Dense(feature_shape)(inner_layer)\n",
        "    return outputs"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuccViYgBK6v"
      },
      "source": [
        "## 인코더\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tG3MH0n1JVLz"
      },
      "source": [
        "* 인코더는 하나의 어텐션을 사용\n",
        "  + encoder self-attention (multi-head self-attention과 동일)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5T0pzBoAnn3"
      },
      "source": [
        "def encoder_modules(inputs, model_dim, ffn_dim, heads):\n",
        "    self_attn = sublayer_connection(inputs, multi_head_attention(inputs, inputs, inputs, model_dim, heads))\n",
        "    outputs = sublayer_connection(self_attn, feed_forward(self_attn, ffn_dim))\n",
        "    return outputs\n",
        "\n",
        "def encoder(inputs, model_dim, ffn_dim, heads, num_layers):\n",
        "    outputs = inputs\n",
        "    for i in range(num_layers):\n",
        "        outputs = encoder_modules(outputs, model_dim, ffn_dim, heads)\n",
        "    return outputs"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcgHRcTEBQqg"
      },
      "source": [
        "## 디코더"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNj-6FLQwT4-"
      },
      "source": [
        "* 디코더는 다음과 같은 구성의 반복으로 이루어짐\n",
        "  1. masked decoder self-attention\n",
        "  2. encoder-decoder attention\n",
        "  3. position-wise FFNN\n",
        "\n",
        "* 디코더에서는 2종류의 어텐션을 사용\n",
        "  1.   masked decoder self-attention\n",
        "    *   디코더에서는 인코더와는 달리 순차적으로 결과를 만들어 내야하기 때문에 다른 어텐션 방법을 사용함\n",
        "    *   디코더 예측 시점 이후의 위치에 attention을 할 수 없도록 masking 처리\n",
        "    *   결국 예측 시점에서 예측은 미리 알고 있는 위치까지만의 결과에 의존\n",
        "  2.   encoder-decoder attention\n",
        "    *   앞서 설명한 multi-head attention과 동일\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B05wr7aARcT"
      },
      "source": [
        "def decoder_module(inputs, encoder_outputs, model_dim, ffn_dim, heads):\n",
        "    masked_self_attn = sublayer_connection(inputs, \n",
        "                                           multi_head_attention(inputs, inputs, inputs,\n",
        "                                                                model_dim, heads, masked=True))\n",
        "    self_attn = sublayer_connection(masked_self_attn,\n",
        "                                    multi_head_attention(masked_self_attn, encoder_outputs, encoder_outputs,\n",
        "                                                         model_dim, heads))\n",
        "    outputs = sublayer_connection(self_attn, feed_forward(self_attn, ffn_dim))\n",
        "    return outputs\n",
        "\n",
        "def decoder(inputs, encoder_outputs, model_dim, ffn_dim, heads, num_layers):\n",
        "    outputs = inputs\n",
        "    for i in range(num_layers):\n",
        "        outputs = decoder_module(outputs, encoder_outputs, model_dim, ffn_dim, heads)\n",
        "    return outputs"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtztlyUB1ERS"
      },
      "source": [
        "## 트랜스포머를 활용한 챗봇"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CGUIAzv6eWs"
      },
      "source": [
        "### konlpy 라이브러리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ae0mHT49v5gy"
      },
      "source": [
        "*    한글을 처리하기 위해 konlpy 라이브러리 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8yf75uG6hBW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e90c37a3-af64-4485-a58d-9e7e984fbacc"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.4.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUMXvK5H1G9H"
      },
      "source": [
        "### 데이터 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miXrjR316mNb"
      },
      "source": [
        "* 처리에 필요한 각종 변수 선언\n",
        "* filters에 해당되는 문자를 걸러주는 정규 표현식 컴파일\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMjn5PfE1GZR"
      },
      "source": [
        "import re\n",
        "\n",
        "filters = '([~.,!?\\'\":;)(])'\n",
        "PAD, STD, END, UNK = '<PADDING>', '<START>', '<END>', '<UNKNOWN>'\n",
        "PAD_INDEX, STD_INDEX, END_INDEX, UNK_INDEX = 0, 1, 2, 3\n",
        "MARKER = [PAD, STD, END, UNK]\n",
        "CHANGE_FILTER = re.compile(filters)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmRFuH2r6oNJ"
      },
      "source": [
        "* 주소에서 데이터를 가져오는 `load_data()` 함수 선언\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmrmdXkePWYb"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def load_data(data_path):\n",
        "    data_df = pd.read_csv(data_path, header=0)\n",
        "    question, answer = list(data_df['Q']), list(data_df['A'])\n",
        "    train_input, eval_input, train_label, eval_label = train_test_split(\n",
        "        question, answer, test_size=0.33, random_state=111\n",
        "    )\n",
        "    return train_input, train_label, eval_input, eval_label"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHuOJHPtPXqq"
      },
      "source": [
        "* 처리에 필요한 단어 사전을 생성하는 `load_vocab()` 함수 선언"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtQL-AP06oSa"
      },
      "source": [
        "def load_vocab(data_path):\n",
        "    data_df = pd.read_csv(data_path, encoding='utf-8')\n",
        "    question, answer = list(data_df['Q']), list(data_df['A'])\n",
        "    if tokenize_as_morph:\n",
        "        question = prepro_like_morphlized(question)\n",
        "        answer = prepro_like_morphlized(answer)\n",
        "\n",
        "    data = []\n",
        "    data.extend(question)\n",
        "    data.extend(answer)\n",
        "    words = data_tokenizer(data)\n",
        "    words = list(set(words))\n",
        "    words[:0] = MARKER\n",
        "\n",
        "    char2idx = {char:idx for idx, char in enumerate(words)}\n",
        "    idx2char = {idx:char for idx, char in enumerate(words)}\n",
        "    return char2idx, idx2char, len(char2idx)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wYtpjv76r5q"
      },
      "source": [
        "* 문자열 데이터를 학습에 사용될 수 있도록 변현하는 `prepro_like_morphlized()` 함수 선언\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bQ3FOva6tg6"
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "\n",
        "def prepro_like_morphlized(data):\n",
        "    morph_analyzer = Okt()\n",
        "    result_data = []\n",
        "    for seq in data:\n",
        "        morphlized_seq = ' '.join(morph_analyzer.morphs(seq.replace(' ', '')))\n",
        "        result_data.append(morphlized_seq)\n",
        "    return result_data"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhsVp4pWPTR3"
      },
      "source": [
        "* 단어 사전을 만들기 위해 단어들을 분리하는 `data_tokenizer()` 함수 선언"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otLI_RUfPR_g"
      },
      "source": [
        "def data_tokenizer(data):\n",
        "    words = []\n",
        "    for sentence in data:\n",
        "        sentence = re.sub(CHANGE_FILTER, '', sentence)\n",
        "        for word in sentence.split():\n",
        "            words.append(word)\n",
        "    return [word for word in words if word]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkKPA-Mx6uaC"
      },
      "source": [
        "* encoder의 입력을 구성하기 위한 함수 `enc_processing()` 선언\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK-yeSThPGsa"
      },
      "source": [
        "def enc_processing(value, dictionary):\n",
        "    sequences_input_index = []\n",
        "    sequences_length = []\n",
        "\n",
        "    if tokenize_as_morph:\n",
        "        value = prepro_like_morphlized(value)\n",
        "\n",
        "    for sequence in value:\n",
        "        seq = re.sub(CHANGE_FILTER, '', sequence)\n",
        "        sequence_index = []\n",
        "        for word in seq.split():\n",
        "            if dictionary.get(word) is not None:\n",
        "                sequence_index.extend([dictionary[word]])\n",
        "            else:\n",
        "                sequence_index.extend([dictionary[UNK]])\n",
        "        if len(sequence_index) > max_len:\n",
        "            sequence_index = sequence_index[:max_len]\n",
        "        sequences_length.append(len(sequence_index))\n",
        "        sequence_index += (max_len - len(sequence_index)) * [dictionary[PAD]]\n",
        "        sequences_input_index.append(sequence_index)\n",
        "    return np.asarray(sequences_input_index), sequences_length"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4mM57_FPIg7"
      },
      "source": [
        "* decoder의 입력을 구성하기 위한 함수 `dec_input_processing()` 선언"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cX_NpcTq6vw6"
      },
      "source": [
        "def dec_input_processing(value, dictionary):\n",
        "    sequences_input_index = []\n",
        "    sequences_length = []\n",
        "\n",
        "    if tokenize_as_morph:\n",
        "        value = prepro_like_morphlized(value)\n",
        "\n",
        "    for sequence in value:\n",
        "        seq = re.sub(CHANGE_FILTER, '', sequence)\n",
        "        sequence_index = []\n",
        "        sequence_index = [dictionary[STD]] + [dictionary[word] for word in seq.split()]\n",
        "        if len(sequence_index) > max_len:\n",
        "            sequence_index = sequence_index[:max_len]\n",
        "        sequences_length.append(len(sequence_index))\n",
        "        sequence_index += (max_len - len(sequence_index)) * [dictionary[PAD]]\n",
        "        sequences_input_index.append(sequence_index)\n",
        "    return np.asarray(sequences_input_index), sequences_length"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otsTEt4FPLJX"
      },
      "source": [
        "* decoder의 출력을 구성하기 위한 함수 `dec_target_processing()` 선언"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeP0PWHEPMma"
      },
      "source": [
        "def dec_target_processing(value, dictionary):\n",
        "    sequences_target_index = []\n",
        "\n",
        "    if tokenize_as_morph:\n",
        "        value = prepro_like_morphlized(value)\n",
        "\n",
        "    for sequence in value:\n",
        "        seq = re.sub(CHANGE_FILTER, '', sequence)\n",
        "        sequence_index = [dictionary[word] for word in seq.split()]\n",
        "        if len(sequence_index) >= max_len:\n",
        "            sequence_index = sequence_index[:max_len - 1] + [dictionary[END]]\n",
        "        else:\n",
        "            sequence_index += [dictionary[END]]\n",
        "        sequence_index += (max_len - len(sequence_index)) * [dictionary[PAD]]\n",
        "        sequences_target_index.append(sequence_index)\n",
        "    return np.asarray(sequences_target_index)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb9vVUng6xDq"
      },
      "source": [
        "* 모델에 데이터를 효율적으로 투입하도록 `train_input_fn()`, `eval_input_fn()` 함수 선언\n",
        "* `rearrange()`는 dataset 객체가 데이터를 어떻게 변형시킬지 정의해둔 함수\n",
        "* dataset.map은 rearrange 함수를 기반으로 데이터를 변형\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAlKV4xF62Uf"
      },
      "source": [
        "def train_input_fn(train_input_enc, train_output_enc, train_target_dec, batch_size):\n",
        "    dataset = tf.compat.v1.data.Dataset.from_tensor_slices((train_input_enc, train_output_enc, train_target_dec))\n",
        "    dataset = dataset.shuffle(buffer_size=len(train_input_enc))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(rearrange)\n",
        "    dataset = dataset.repeat()\n",
        "    iterator = dataset.make_one_shot_iterator()\n",
        "    return iterator.get_next()\n",
        "\n",
        "def eval_input_fn(eval_input_enc, eval_output_enc, eval_target_dec, batch_size):\n",
        "    dataset = tf.compat.v1.data.Dataset.from_tensor_slices((eval_input_enc, eval_output_enc, eval_target_dec))\n",
        "    dataset = dataset.shuffle(buffer_size=len(eval_input_enc))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(rearrange)\n",
        "    dataset = dataset.repeat()\n",
        "    iterator = dataset.make_one_shot_iterator()\n",
        "    return iterator.get_next()\n",
        "\n",
        "def rearrange(input, output, target):\n",
        "    features = {'input':input, 'output':output}\n",
        "    return features, target"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "is-GhUDN62xC"
      },
      "source": [
        "* 모델의 예측은 배열로 생성되기 때문에 이를 확인하기 위해선 문자열로 변환이 필요\n",
        "* 예측을 문자열로 변환해주는 `pred2string()` 함수 선언\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCfwWXhb64Cc"
      },
      "source": [
        "def pred2string(value, dictionary):\n",
        "    sentence_string = []\n",
        "    is_finished = False\n",
        "    for v in value:\n",
        "        sentence_string = [dictionary[index] for index in v['indice']]\n",
        "\n",
        "    answer = ''\n",
        "    for word in sentence_string:\n",
        "        if word == END:\n",
        "            is_finished = True\n",
        "            break\n",
        "        if word != PAD and word != END:\n",
        "            answer += word + ' '\n",
        "\n",
        "    return answer, is_finished"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwp9Nnwz7UoG"
      },
      "source": [
        "* 챗봇 데이터 URL: https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\n",
        "* 데이터 주소에서 데이터를 읽어들여 단어 사전과 사용 데이터 구성"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize_as_morph = True\n",
        "data_path = 'https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv'\n",
        "\n",
        "char2idx, idx2char, len_vocab = load_vocab(data_path)\n",
        "train_input, train_label, eval_input, eval_label = load_data(data_path)"
      ],
      "metadata": {
        "id": "PWLi_oKTRNgP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cVd7AOKinqn"
      },
      "source": [
        "### 모델 구성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqLJ0a6r49yi"
      },
      "source": [
        "* 앞서 작성한 트랜스포머 모델을 결합해 학습에 사용할 모델을 구성함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNeeXoZginvj"
      },
      "source": [
        "def model(features, labels, mode, params):\n",
        "    TRAIN = mode == tf.estimator.ModeKeys.TRAIN\n",
        "    EVAL = mode == tf.estimator.ModeKeys.EVAL\n",
        "    PREDICT = mode == tf.estimator.ModeKeys.PREDICT\n",
        "\n",
        "    position_encode = positional_encoding(params['embedding_size'], params['max_len'])\n",
        "    embedding_initializer = 'glorot_normal' if params['xavier_initializer'] else 'uniform'\n",
        "\n",
        "    embedding = tf.keras.layers.Embedding(params['len_vocab'], params['embedding_size'],\n",
        "                                          embeddings_initializer=embedding_initializer)\n",
        "\n",
        "    x_embedded_matrix = embedding(features['input']) + position_encode\n",
        "    y_embedded_matrix = embedding(features['output']) + position_encode\n",
        "\n",
        "    encoder_outputs = encoder(x_embedded_matrix, params['model_hidden_size'], params['ffn_hidden_size'],\n",
        "                              params['attention_head_size'], params['layer_size'])\n",
        "    decoder_outputs = decoder(y_embedded_matrix, encoder_outputs, \n",
        "                              params['model_hidden_size'], params['ffn_hidden_size'],\n",
        "                              params['attention_head_size'], params['layer_size'])\n",
        "    \n",
        "    logits = tf.keras.layers.Dense(params['len_vocab'])(decoder_outputs)\n",
        "    predict = tf.argmax(logits, 2)\n",
        "\n",
        "    if PREDICT:\n",
        "        predictions = {'indice':predict, 'logits':logits}\n",
        "        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
        "\n",
        "    labels_ = tf.one_hot(labels, params['len_vocab'])\n",
        "    loss = tf.reduce_mean(tf.compat.v1.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels_))\n",
        "    accuracy = tf.compat.v1.metrics.accuracy(labels=labels, predictions=predict)\n",
        "    metrics = {'accuracy':accuracy}\n",
        "    tf.summary.scalar('accuracy', accuracy[1])\n",
        "\n",
        "    if EVAL:\n",
        "        return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)\n",
        "\n",
        "    assert TRAIN\n",
        "    optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=params['learning_rate'])\n",
        "    train_op = optimizer.minimize(loss, global_step=tf.compat.v1.train.get_global_step())\n",
        "    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7PrLEWE1JCs"
      },
      "source": [
        "### 모델 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gy_Opm_A7DKC"
      },
      "source": [
        "*   필요한 각종 인자들을 설정\n",
        "*   인자에 따라 학습 결과가 달라질 수 있기 때문에 세심한 조정이 필요\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKGYuqmH6_kj"
      },
      "source": [
        "max_len = 25\n",
        "epoch = 5000\n",
        "batch_size = 256\n",
        "embedding_size = 100\n",
        "model_hidden_size = 100\n",
        "ffn_hidden_size = 100\n",
        "attention_head_size = 100\n",
        "lr = 0.001\n",
        "layer_size = 3\n",
        "xavier_initializer = True"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaXalEy57ODq"
      },
      "source": [
        "*   앞서 선언한 processing 함수로 데이터를 모델에 투입할 수 있도록 가공\n",
        "*   평가 데이터에도 동일하게 가공"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWlgWWIq1KSh"
      },
      "source": [
        "train_input_enc, train_input_enc_length = enc_processing(train_input, char2idx)\n",
        "train_input_dec, train_input_dec_length = dec_input_processing(train_label, char2idx)\n",
        "train_target_dec = dec_target_processing(train_label, char2idx)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_input_enc, eval_input_enc_length = enc_processing(eval_input, char2idx)\n",
        "eval_input_dec, eval_input_dec_length = dec_input_processing(eval_label, char2idx)\n",
        "eval_target_dec = dec_target_processing(eval_label, char2idx)"
      ],
      "metadata": {
        "id": "SHYRGLWgY1-5"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZGgZzWs7Mr7"
      },
      "source": [
        "* 앞서 선언한 함수를 통해 모델을 선언하고 학습\n",
        "* `tf.estimator`를 사용해 간편하게 학습 모듈 구성\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9vjc3Ck7F4J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64a40220-14ab-45fd-9808-88577538a507"
      },
      "source": [
        "transformer = tf.estimator.Estimator(\n",
        "    model_fn = model,\n",
        "    params = {'embedding_size':embedding_size,\n",
        "              'model_hidden_size':model_hidden_size,\n",
        "              'ffn_hidden_size':ffn_hidden_size,\n",
        "              'attention_head_size':attention_head_size,\n",
        "              'learning_rate':lr,\n",
        "              'len_vocab':len_vocab,\n",
        "              'layer_size':layer_size,\n",
        "              'max_len':max_len,\n",
        "              'xavier_initializer':xavier_initializer}\n",
        ")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpitqirxmi\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpitqirxmi', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wl_pwUiw7INZ"
      },
      "source": [
        "* 학습한 모델을 사용해 챗봇을 사용\n",
        "* 예측 결과를 문자열로 변환할 때는 앞서 선언한 `pred2string()` 함수를 이용\n",
        "* 입력에 대한 응답이 생성되는 것을 확인할 수 있음\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COO-0PcS7Hy5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6ce7e09-9863-450a-bea1-7e122088e179"
      },
      "source": [
        "transformer.train(\n",
        "    input_fn=lambda: train_input_fn(train_input_enc, train_input_dec, train_target_dec, batch_size),\n",
        "    steps=epoch\n",
        ")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/training_util.py:397: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From <ipython-input-19-ca5d73b22eec>:7: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This is a deprecated API that should only be used in TF 1 graph mode and legacy TF 2 graph mode available through `tf.compat.v1`. In all other situations -- namely, eager mode and inside `tf.function` -- you can consume dataset elements using `for elem in dataset: ...` or by explicitly creating iterator via `iterator = iter(dataset)` and fetching its elements via `values = next(iterator)`. Furthermore, this API is not available in TF 2. During the transition from TF 1 to TF 2 you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)` to create a TF 1 graph mode style iterator for a dataset created through TF 2 APIs. Note that this should be a transient state of your code base as there are in general no guarantees about the interoperability of TF 1 and TF 2 code.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpitqirxmi/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "INFO:tensorflow:loss = 9.562811, step = 0\n",
            "INFO:tensorflow:global_step/sec: 5.11948\n",
            "INFO:tensorflow:loss = 1.50172, step = 100 (19.539 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.88206\n",
            "INFO:tensorflow:loss = 1.4040189, step = 200 (17.002 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.8945\n",
            "INFO:tensorflow:loss = 1.2457306, step = 300 (16.964 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.89268\n",
            "INFO:tensorflow:loss = 1.040566, step = 400 (16.972 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.87197\n",
            "INFO:tensorflow:loss = 0.8943355, step = 500 (17.028 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.82782\n",
            "INFO:tensorflow:loss = 0.80213827, step = 600 (17.327 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.67485\n",
            "INFO:tensorflow:loss = 0.675209, step = 700 (17.454 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.76536\n",
            "INFO:tensorflow:loss = 0.5948265, step = 800 (17.343 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.75777\n",
            "INFO:tensorflow:loss = 0.4276776, step = 900 (17.370 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.72829\n",
            "INFO:tensorflow:loss = 0.36752594, step = 1000 (17.457 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.70728\n",
            "INFO:tensorflow:loss = 0.28205657, step = 1100 (17.522 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.6815\n",
            "INFO:tensorflow:loss = 0.24069786, step = 1200 (17.601 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.67732\n",
            "INFO:tensorflow:loss = 0.17322011, step = 1300 (17.614 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.58532\n",
            "INFO:tensorflow:loss = 0.123016946, step = 1400 (17.903 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.64076\n",
            "INFO:tensorflow:loss = 0.081911765, step = 1500 (17.729 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.63748\n",
            "INFO:tensorflow:loss = 0.0630889, step = 1600 (17.739 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.63944\n",
            "INFO:tensorflow:loss = 0.04863924, step = 1700 (17.732 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.66815\n",
            "INFO:tensorflow:loss = 0.030882537, step = 1800 (17.642 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.64954\n",
            "INFO:tensorflow:loss = 0.023535432, step = 1900 (17.701 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.62082\n",
            "INFO:tensorflow:loss = 0.019979585, step = 2000 (17.791 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.61261\n",
            "INFO:tensorflow:loss = 0.017266713, step = 2100 (17.813 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.62072\n",
            "INFO:tensorflow:loss = 0.013773683, step = 2200 (17.794 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.64253\n",
            "INFO:tensorflow:loss = 0.011243119, step = 2300 (17.723 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.6723\n",
            "INFO:tensorflow:loss = 0.0114290295, step = 2400 (17.627 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.63928\n",
            "INFO:tensorflow:loss = 0.009172269, step = 2500 (17.735 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.54733\n",
            "INFO:tensorflow:loss = 0.008631709, step = 2600 (18.027 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.60961\n",
            "INFO:tensorflow:loss = 0.007240855, step = 2700 (17.826 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.61657\n",
            "INFO:tensorflow:loss = 0.006203035, step = 2800 (17.805 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.63865\n",
            "INFO:tensorflow:loss = 0.0071230466, step = 2900 (17.734 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.62816\n",
            "INFO:tensorflow:loss = 0.0058521167, step = 3000 (17.769 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.62051\n",
            "INFO:tensorflow:loss = 0.0045118914, step = 3100 (17.791 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.65375\n",
            "INFO:tensorflow:loss = 0.004362161, step = 3200 (17.687 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.65457\n",
            "INFO:tensorflow:loss = 0.5155681, step = 3300 (17.684 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 3380...\n",
            "INFO:tensorflow:Saving checkpoints for 3380 into /tmp/tmpitqirxmi/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 3380...\n",
            "INFO:tensorflow:global_step/sec: 5.40452\n",
            "INFO:tensorflow:loss = 0.06715818, step = 3400 (18.502 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.66233\n",
            "INFO:tensorflow:loss = 0.022312831, step = 3500 (17.662 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.66121\n",
            "INFO:tensorflow:loss = 0.009487513, step = 3600 (17.665 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.65525\n",
            "INFO:tensorflow:loss = 0.006808402, step = 3700 (17.682 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.61349\n",
            "INFO:tensorflow:loss = 0.007033236, step = 3800 (17.814 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.66769\n",
            "INFO:tensorflow:loss = 0.0055191745, step = 3900 (17.645 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.65554\n",
            "INFO:tensorflow:loss = 0.0044866283, step = 4000 (17.681 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.66271\n",
            "INFO:tensorflow:loss = 0.0046207793, step = 4100 (17.659 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.66914\n",
            "INFO:tensorflow:loss = 0.0040593673, step = 4200 (17.641 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.65004\n",
            "INFO:tensorflow:loss = 0.0037883236, step = 4300 (17.698 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.64776\n",
            "INFO:tensorflow:loss = 0.003557604, step = 4400 (17.705 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.63156\n",
            "INFO:tensorflow:loss = 0.003023513, step = 4500 (17.758 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.61486\n",
            "INFO:tensorflow:loss = 0.0022957595, step = 4600 (17.810 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.61846\n",
            "INFO:tensorflow:loss = 0.0026771582, step = 4700 (17.799 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.61677\n",
            "INFO:tensorflow:loss = 0.003710174, step = 4800 (17.803 sec)\n",
            "INFO:tensorflow:global_step/sec: 5.62311\n",
            "INFO:tensorflow:loss = 0.0026785317, step = 4900 (17.784 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmpitqirxmi/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
            "INFO:tensorflow:Loss for final step: 0.0026622245.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.estimator.EstimatorV2 at 0x7f51306496d0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = transformer.evaluate(\n",
        "    input_fn=lambda: eval_input_fn(eval_input_enc, eval_input_dec, eval_target_dec, batch_size)\n",
        ")\n",
        "print(\"accuracy: {accuracy: 0.4f}\".format(**eval_result))"
      ],
      "metadata": {
        "id": "CimXHssZcqmv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "18a919ca-4d5a-4054-bcd9-ec5e9c74cc69"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2022-06-13T02:37:35\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpitqirxmi/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-403a3e603a46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m eval_result = transformer.evaluate(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meval_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_input_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_input_dec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_target_dec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"accuracy: {accuracy: 0.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0meval_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, input_fn, steps, hooks, checkpoint_path, name)\u001b[0m\n\u001b[1;32m    476\u001b[0m           \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m           \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m   def _actual_eval(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_actual_eval\u001b[0;34m(self, input_fn, strategy, steps, hooks, checkpoint_path, name)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_convert_eval_steps_to_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0meval_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0mall_hooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_hooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m             output_dir=self.eval_dir(name))\n\u001b[0m\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_evaluate_run\u001b[0;34m(self, checkpoint_path, scaffold, update_op, eval_dict, all_hooks, output_dir)\u001b[0m\n\u001b[1;32m   1663\u001b[0m         \u001b[0mfinal_ops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_hooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1665\u001b[0;31m         config=self._session_config)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m     \u001b[0mcurrent_global_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGLOBAL_STEP\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/evaluation.py\u001b[0m in \u001b[0;36m_evaluate_once\u001b[0;34m(checkpoint_path, master, scaffold, eval_ops, feed_dict, final_ops, final_ops_feed_dict, hooks, config)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meval_ops\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m   \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Inference Time : {:0.5f}s'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m         run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1313\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m             run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1316\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m         logging.info(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1399\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1402\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1472\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m         \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m         run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1232\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 968\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    969\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1191\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1192\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1369\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1371\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1372\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1375\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1359\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1361\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1453\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1454\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1455\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNcrVf2z1LSM"
      },
      "source": [
        "### 예측"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5lY9DrW8eSK"
      },
      "source": [
        "* 학습한 모델을 사용해 챗봇을 사용\n",
        "* 예측 결과를 문자열로 변환할 때는 앞서 선언한 `pred2string()` 함수를 이용\n",
        "* 입력에 대한 응답이 생성되는 것을 확인할 수 있음\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9IQaBx4Qw8J"
      },
      "source": [
        "def chatbot(sentence):\n",
        "    pred_input_enc, pred_input_enc_length = enc_processing([sentence], char2idx)\n",
        "    pred_input_dec, pred_input_dec_length = dec_input_processing([''], char2idx)\n",
        "    pred_target_dec = dec_target_processing([''], char2idx)\n",
        "\n",
        "    for i in range(max_len):\n",
        "        if i > 0:\n",
        "            pred_input_dec, pred_input_dec_length = dec_input_processing([answer], char2idx)\n",
        "            pred_target_dec = dec_target_processing([answer], char2idx)\n",
        "\n",
        "        predictions = transformer.predict(\n",
        "            input_fn=lambda: eval_input_fn(pred_input_enc, pred_input_dec, pred_target_dec, 1)\n",
        "        )\n",
        "        answer, finished = pred2string(predictions, idx2char)\n",
        "\n",
        "        if finished:\n",
        "            break\n",
        "\n",
        "        return answer"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjHZKvJ31MAU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "5d3ece50-57aa-4e69-d766-fa2248410748"
      },
      "source": [
        "chatbot('안녕?')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpitqirxmi/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-b1680fbe1052>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchatbot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'안녕?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-29-6549d8baf1c8>\u001b[0m in \u001b[0;36mchatbot\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meval_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_input_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_input_dec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_target_dec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         )\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0manswer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinished\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred2string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx2char\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfinished\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-431057b7c68f>\u001b[0m in \u001b[0;36mpred2string\u001b[0;34m(value, dictionary)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msentence_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mis_finished\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0msentence_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'indice'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_fn, predict_keys, hooks, checkpoint_path, yield_single_examples)\u001b[0m\n\u001b[1;32m    640\u001b[0m             hooks=all_hooks) as mon_sess:\n\u001b[1;32m    641\u001b[0m           \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             \u001b[0mpreds_evaluated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    643\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0myield_single_examples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m               \u001b[0;32myield\u001b[0m \u001b[0mpreds_evaluated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m         run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1313\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m             run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1316\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m         logging.info(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1399\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1402\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1472\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m         \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m         run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1232\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 968\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    969\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1191\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1192\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1369\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1371\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1372\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1375\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1359\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1361\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1453\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1454\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1455\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mjRZwyLQ_gP"
      },
      "source": [
        "chatbot('너 누구냐?')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7AJCsXRTqJx"
      },
      "source": [
        "chatbot('뭐 먹었어?')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M8mfoUfeAWQ"
      },
      "source": [
        "chatbot('놀고 싶다.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5mrdGRaem6v"
      },
      "source": [
        "chatbot('이제 그만 잘래')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}